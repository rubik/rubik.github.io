<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel=apple-touch-icon sizes=180x180 href=/static/icons/apple-touch-icon.png><link rel=icon type=image/png href=/static/icons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/static/icons/favicon-16x16.png sizes=16x16><link rel=manifest href=/static/icons/manifest.json><link rel=mask-icon href=/static/icons/safari-pinned-tab.svg color=#2ae2b1><link rel="shortcut icon" href=/static/icons/favicon.ico><meta name=msapplication-config content="/static/icons/browserconfig.xml"><meta name=theme-color content="#ffffff"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Rubik:wght@400&display=swap" rel=stylesheet><link rel=stylesheet href=https://signal-to-noise.xyz/scss/main.min.6d905468f4703eed3a6be770925feacadfbddf831f38d2d000062749b1b4e74a.css integrity="sha256-bZBUaPRwPu06a+dwkl/qyt+934MfONLQAAYnSbG050o="><script async src="https://cdn.panelbear.com/analytics.js?site=7moiko9QLML"></script>
<script>window.panelbear=window.panelbear||function(){(window.panelbear.q=window.panelbear.q||[]).push(arguments)},panelbear("config",{site:"7moiko9QLML"})</script><title>An overview of great tools for data science</title><meta name=description content="Overview of the most useful tools for data science: mainly Python and Javscript"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/signal-to-noise.xyz\/post\/overview-python-data-science\/"},"headline":"An overview of great tools for data science","name":"An overview of great tools for data science","datePublished":"2016-11-06","dateModified":"20161106-00:00:00.000","author":{"@type":"Person","name":"Michele Lacchia"},"publisher":{"@type":"Organization","name":"Signal to Noise","logo":{"@type":"ImageObject","url":"https:\/\/signal-to-noise.xyz\/static\/images\/signal-to-noise.png"}},"description":"Overview of the most useful tools for data science: mainly Python and Javscript","keywords":"python,javascript,big-list"}</script></head><body><div class=container><header role=banner><div class=header-logo><a href=/><img src=/static/images/signal-to-noise.png width=60 height=60 alt="Signal to Noise"></a></div></header><main role=main><article class=main-content><div class=post-meta><h1>An overview of great tools for data science</h1><span><time datetime=2016-11-06>November 06, 2016</time>, Michele Lacchia</span></div><div class=post-tags><a href=https://signal-to-noise.xyz//tags/python>python</a>
<a href=https://signal-to-noise.xyz//tags/javascript>javascript</a>
<a href=https://signal-to-noise.xyz//tags/big-list>big-list</a></div><figure><img itemprop=image title="A graph" src=/static/images/world-graph.jpg><div class=copyright>Travel vector designed by&nbsp;<a href=https://www.freepik.com/free-photos-vectors/travel>Freepik</a></div></figure><p>This post presents an overview of the most useful tools for data
science-related tasks. It is not meant to be a complete list, but rather a
brief summary of the tools I&rsquo;ve found repeatedly useful, with a couple new ones
that show great promise. The idea came from my last project (<a href=/post/texasdeathrow/>Exploration of
Texas Death row data</a>), where I ended up using quite a
lot of Python packages, without having planned it from the start. This post is
meant to be a very syntetic reference, so that it can be useful to someone
comparing different solutions for a certain problem.</p><p>The overview will be comprised mainly of Python packages and some Javascript
tools in the visualization section, because that&rsquo;s what I am comfortable
working with. I also intend to start learning R in the near future, so maybe
there will be a follow-up with R libraries as well. Without further ado, let&rsquo;s
get started. This is what will be covered:</p><ul><li><a href=#foundations>Foundations (the SciPy stack)</a></li><li><a href=#scr-nlp>Scraping, data mining and NLP</a></li><li><a href=#data-viz>Data visualization</a></li><li><a href=#stat>Statistical modeling</a></li><li><a href=#ml>Machine-learning</a></li></ul><hr><p><a name=foundations></a></p><h2 id=foundations-the-scipy-stack>Foundations (the SciPy stack)</h2><h4 id=numpy>NumPy</h4><p>Without doubt, <a href=https://www.numpy.org/ target=_blank rel="noopener noreferrer">NumPy</a> is the most foundamental package
for efficient scientific computing in Python. NumPy provides multi-dimensional
array objects and sophisticated broadcasting functions. Its core is written in
C, C++ and Fortran code for efficiency. Many packages in this list are built
upon NumPy, which is a must-know in the Python scientific computing landscape.</p><h4 id=scipy-library>SciPy library</h4><p>The <a href=https://scipy.org/ target=_blank rel="noopener noreferrer">SciPy library</a> is an extension to
NumPy that adds numerous algorithms for integration and optimization problems,
signal processing, statistics, linear algebra, as well as routines and objects
to work with sparse data. This library is huge, but it&rsquo;s well documented, with
explanations and examples.</p><h4 id=matplotlib>Matplotlib</h4><p><a href=https://matplotlib.org/ target=_blank rel="noopener noreferrer">Matplotlib</a> is the standard Python plotting library
that produces publication-quality plots out of the box. It focuses on 2D
graphs, but it can produce 3D visualizations as well. It&rsquo;s pretty low-level,
meaning that plotting is not really straightforward. However, the library is
completely flexible, and you can customize it to make any kind of plot you
want.</p><h4 id=pandas>Pandas</h4><p><a href=https://pandas.pydata.org/ target=_blank rel="noopener noreferrer">Pandas</a> is a library for operating with table-like
structures. Its powerful <code>DataFrame</code> object makes it easy to reshape, merge,
slice and perform computations on datasets. It can also read and write data to
a wealth of formats, including JSON, CSV and Excel.</p><h4 id=jupyter>Jupyter</h4><p><a href=https://jupyter.org/ target=_blank rel="noopener noreferrer">Project Jupyter</a> was born out of the IPython Project in
2014 as it evolved to support interactive data science and scientific computing
across all programming languages. Its notebook is a web application that allows
to create documents containing live code, equations, interactive visualizations
and text. It&rsquo;s most commonly used with the IPython kernel, but it&rsquo;s not
restricted to the Python language.</p><p>I&rsquo;ve found the notebook to be extremely useful to explore datasets and perform
data cleaning and visualization. In fact, when presented with a new dataset, I
always fire up a notebook and delve into it.</p><p><a name=scr-nlp></a></p><h2 id=scraping-data-mining-and-natural-language-processing-nlp>Scraping, data mining and natural language processing (NLP)</h2><h4 id=scrapy>Scrapy</h4><p><a href=https://scrapy.org/ target=_blank rel="noopener noreferrer">Scrapy</a> is a Python library to extract data from
websites. It builds on <a href=https://twisted.org/ target=_blank rel="noopener noreferrer">Twisted</a> to schedule
asynchronous requests, resulting in extremely fast crawlers. It&rsquo;s also very
easy to extend. Scrapy requires a whole project to run, but it provides command
to build them from base templates (<code>scrapy startproject</code>, <code>scrapy genspider</code>),
so it&rsquo;s both easy and quick to get up and running.</p><p>Scrapy is my tool of choice when I have to scrape data and I have yet to
encounter something that it cannot do. For example, you can plug
<a href=https://splash.readthedocs.io/en/stable/ target=_blank rel="noopener noreferrer">Splash</a> to render Javascript, or
<a href=https://www.zyte.com/smart-proxy-manager/ target=_blank rel="noopener noreferrer">Smart Proxy Manager (formerly
Crawlera)</a> (paid service) to route
requests through a pool of proxies, which are managed automatically.</p><h4 id=stocktalk>Stocktalk</h4><p><a href=https://github.com/anfederico/Stocktalk target=_blank rel="noopener noreferrer">Stocktalk</a> is a data collection
toolkit to scrape stock data from social media and explore it. The library can
also perform sentiment analysis over the collected data.</p><h4 id=nltk>NLTK</h4><p><a href=https://www.nltk.org/ target=_blank rel="noopener noreferrer">NLTK</a>, or Natural Language Toolkit, is a set of
libraries to work with human language data: it supports tokenization, stemming,
tagging, parsing and classification. It also includes over 50 corpora and
lexical resources. I found its documentation to be lacking in certain areas,
but there is also a <a href=https://www.nltk.org/book/ target=_blank rel="noopener noreferrer">book</a>, written by the creators
of NLTK, which provides an introduction to NLP with Python.</p><h4 id=textblob>Textblob</h4><p><a href=https://textblob.readthedocs.io/en/dev/ target=_blank rel="noopener noreferrer">Textblob</a> simple and modern API for
many NLP tasks such as tagging, sentiment analysis, classification and
translation, among others.</p><p>I have used it mainly for sentiment analysis, and it provides two analyzers,
which are useful in different contexts. The first one is TextBlob&rsquo;s own
analyzer, which works by querying a sentiment lexicon. Each word in the lexicon
has polarity and subjectivity scores, along with the intensity of each word.
The score of a sentence is the aggregate of the single word scores. The
analyzer is capable of factoring in negations and intensity modifiers. The
other one is based on NLTK&rsquo;s <code>NaiveBayesClassifier</code>, which is a model trained
on a corpus of movie reviews. In my own projects, I&rsquo;ve found that the second
one gives better results when the text is composed of actual reviews or when
there is similar lexicon involved. On the other hand, TextBlob&rsquo;s own analyzer
fares better in more general contexts.</p><h4 id=gensim>Gensim</h4><p><a href=https://radimrehurek.com/gensim/ target=_blank rel="noopener noreferrer">Gensim</a> is a Python library that focuses on
semantic analysis, and mainly for topic modeling. It&rsquo;s quite comprehensive:
including several model (LDA, LSI, TF-IDF, LogEntropy, HDP, etc.) and also
functions for summarization and similarity queries. Gensim was built with large
corpora in mind, and it&rsquo;s therefore very efficient, featuring ad-hoc routines
for distributed computing as well.</p><h4 id=spacyio>spaCy.io</h4><p><a href=https://spacy.io target=_blank rel="noopener noreferrer">spaCy.io</a> is a new library for &ldquo;industrial-strength NLP&rdquo;
that claims to be the fastest in the world. It&rsquo;s a very comprehensive library,
and it allows seamless interoperability with the other Python libraries in the
NLP space. I have yet to try it, but it looks really promising.</p><p><a name=data-viz></a></p><h2 id=data-visualization>Data visualization</h2><h4 id=seaborn>seaborn</h4><p><a href=https://seaborn.pydata.org/index.html target=_blank rel="noopener noreferrer">Seaborn</a> is based on Matplotlib&rsquo;s core
and adds several features (heat maps, violin plots, scatter plots with
marginals, etc.). Seaborn focuses on statistical visualization. Its default
styles are also much more sophisticated than Matplotlib&rsquo;s default ones, and
they are better looking too.</p><h4 id=altair>Altair</h4><p><a href=https://altair-viz.github.io/ target=_blank rel="noopener noreferrer">Altair</a> is a declarative visualization library
for Python, based on Vega-Lite (see below). Its API is elegant and concise, and
that&rsquo;s what I like about Altair: it lets you generate complex charts with very
few lines of code. Actually, all Altair does is generate JSON that is then fed
to the Javascript library Vega-Lite. It&rsquo;s very easy to display Altair plots in
Jupyter notebooks.</p><h4 id=bokeh>Bokeh</h4><p><a href=https://bokeh.pydata.org/en/latest/ target=_blank rel="noopener noreferrer">Bokeh</a> is a Python visualization library
that targets the browser and focuses on interactivity. Its goal is to provide
elegant and concise construction of graphics in the style of D3.js (see below).
It&rsquo;s very easy to embed Bokeh graphics in Jupyter notebooks.</p><h4 id=folium>Folium</h4><p><a href=https://python-visualization.github.io/folium/ target=_blank rel="noopener noreferrer">Folium</a> is a library that brings the
mapping strengths of the Leaflet library to Python. It is capable of
producing interactive maps of different kinds, with different tiles. It&rsquo;s very
easy to embed Folium maps in Jupyter notebooks.</p><p>Leaflet is a Javascript library for the creation of mobile-friendly interactive
maps. It is designed with simplicity and performance in mind, and its code is
exceptionally small, but extensible.</p><h4 id=gmaps>gmaps</h4><p><a href=https://jupyter-gmaps.readthedocs.io/en/latest/ target=_blank rel="noopener noreferrer">gmaps</a> is a Jupyter extension
for embedding interactive Google Maps in Jupyter notebooks. It supports various
layer types: markers and symbols, heatmaps and weighted heatmaps. It&rsquo;s very
easy to use, but it requires an API key from Google.</p><h4 id=d3js-vega-vega-lite>D3.js (Vega, Vega-lite)</h4><p><a href=https://d3js.org/ target=_blank rel="noopener noreferrer">D3.js</a> is a giant in Javascript&rsquo;s visualization space. It
is a library that binds data to the document model (DOM), and then applies
data-driven transformations. It&rsquo;s very fast and emphasizes web standards.</p><p><a href=https://vega.github.io/vega/ target=_blank rel="noopener noreferrer">Vega</a> is a visualization grammar that leverages
D3.js in its implementation and generates graphics from JSON.
<a href=https://vega.github.io/vega-lite/ target=_blank rel="noopener noreferrer">Vega-lite</a> is a high-level visualization
grammar that can be compiled to Vega. Vega-lite specifications are usually
succient and expressive, with supports for data transformations and visual
transformations.</p><p><a name=stat></a></p><h2 id=statistical-modeling>Statistical modeling</h2><h4 id=statsmodels>statsmodels</h4><p><a href=https://www.statsmodels.org/stable/index.html target=_blank rel="noopener noreferrer">Statsmodels</a> is the standard
library for estimating statistical models and performing statistical tests in
Python. It is fully-featured and among other things, it includes: linear
regression models, generalized linear models, discrete choice models and models
for time series analysis. The library also exposes plotting functions that work
on top of Matplotlib. The development appears to have been slowed down, but
it&rsquo;s still ongoing.</p><h4 id=tsfresh>tsfresh</h4><p><a href=https://tsfresh.readthedocs.io/en/latest/ target=_blank rel="noopener noreferrer">tsfresh</a> is a new Python library
that allows automatic extraction of hundreds of features from time series. At
the time of writing, tsfresh is very young, being only 12 days old. However,
it&rsquo;s extremely useful and quickly gained a lot of traction.</p><p><a name=ml></a></p><h2 id=machine-learning>Machine learning</h2><h4 id=scikit-learn>scikit-learn</h4><p><a href=https://scikit-learn.org/stable/ target=_blank rel="noopener noreferrer">scikit-learn</a> is the most popular machine
learning library for Python. It is built on NumPy and SciPy, and it&rsquo;s
fully-featured, including a broad range of models for classification,
regression, clustering, dimensionality reduction, and lots of utility classes
for preprocessing.</p><p>As a library, scikit-learn really stands out. It&rsquo;s actively developed and has
an outstanding documentation, which couples an API reference with a user guide.
Among scikit-learn&rsquo;s contributors there are many machine learning experts.</p><h4 id=tensorflow>Tensorflow</h4><p><a href=https://www.tensorflow.org/ target=_blank rel="noopener noreferrer">Tensorflow</a> is a machine learning toolkit
developed by Google, with a C++ core and a Python frontend. It features
automatic differentiation and it&rsquo;s particularly ported: it can be used on
mobile devices or large distributed systems with little modification to the
code. With Tensorflow, one defines the neural network in a symbolic way, or how
the data flows.</p><h4 id=theano>Theano</h4><p><a href=https://pypi.org/project/Theano/ target=_blank rel="noopener noreferrer">Theano</a> uses NumPy-like syntax to optimize
and evaluate mathematical expressions. It also supports automatic
differentiation. What sets Theano apart is that it takes advantage of the
computer&rsquo;s GPU. Theano&rsquo;s speed makes it especially valuable for deep learning
and other computationally complex tasks.</p><h4 id=lasagne>Lasagne</h4><p><a href=https://lasagne.readthedocs.io/en/latest/ target=_blank rel="noopener noreferrer">Lasagne</a> is a lightweight library
for building and training neural networks in Python. Lasagne uses Theano for
its computation and therefore can make use of the GPU.</p><h4 id=scikit-neuralnetwork>scikit-neuralnetwork</h4><p><a href=https://scikit-neuralnetwork.readthedocs.io/en/latest/index.html target=_blank rel="noopener noreferrer">sknn</a> is a
Python library that implements multi-layer perceptrons and is compatible with
scikit-learn&rsquo;s API. The library supports both regressors and classifiers and
uses Lasagne and Theano behind the scenes.</p></article></main><div id=replybox class=comments></div><script>window.replybox={site:"W3RG8mGY7K"}</script><script src=https://cdn.getreplybox.com/js/embed.js defer></script><footer role=contentinfo><div class=hr></div><div class=footer-links><ul><li><script>document.write("<a href='mai&#108;to&#58;&#109;ich&#101;&#108;%65l%"+"6"+"1"+"c"+"c"+"%"+"6"+"8"+"i"+"a"+"%"+"&"+"#"+"5"+"2"+";"+"0"+"%"+"6"+"&"+"#"+"5"+"5"+";"+"&"+"#"+"1"+"0"+"9"+";"+"&"+"#"+"9"+"7"+";"+"&"+"#"+"1"+"0"+"5"+";"+"l"+"%"+"&"+"#"+"5"+"0"+";"+"E"+"%"+"6"+"3"+"o"+"m"+"'"+">"+"E"+"m"+"a"+"i"+"&"+"#"+"1"+"0"+"8"+";"+"<"+"/"+"a"+">")</script></li><li><a href=https://github.com/rubik/ target=_blank rel=noopener>GitHub</a></li><li><a href=https://www.linkedin.com/in/michele-lacchia/ target=_blank rel=noopener>LinkedIn</a></li><li><a href=/page/about/>About me</a></li><li><a href=http://feeds.feedburner.com/signal-to-noise>RSS</a></li></ul></div><div class=copyright>Created by Michele Lacchia, built with Hugo</div></footer></div><script defer src=//instant.page/5.1.1 type=module integrity=sha384-MWfCL6g1OTGsbSwfuMHc8+8J2u71/LA8dzlIN3ycajckxuZZmF+DNjdm7O6H3PSq></script></body></html>